\section{Introduction}\label{sec:intro}

Motivations for modelling argument convincingness:
\begin{itemize}
  \item Learning about a controversial topic often requires reading large amounts of text, often with much duplicate information, in order to understand different points of view
  \item Points of view on controversial topics are often presented as arguments for or against a particular position
  \item Finding well-written arguments could allow better understanding of why people hold particular opinions
  \item Identifying arguments that are considered convincing to a particular group of people helps understand who holds which point of view
  \item Tools that identify convincing arguments could therefore assist in making better decisions and analysing public opinion
\end{itemize}

Pairwise preferences provide a way for multiple people to communicate the relative convincingness of arguments:
\begin{itemize}
  \item Implicit preferences can be elicited from user actions, such as selecting a document from a list given its summary to read in more detail
  \item Explicit preferences can be easier to provide than ratings or classifications
  \item Since preferences are relative, they avoid calibration issues caused by multiple people using ratings (e.g. Mary rarely awards 5 stars to movies she likes, John frequently awards 5 stars)
\end{itemize}
  
Previous work on predicting convincingness:
\begin{itemize}
  \item \cite{habernal2016argument} shows that it is possible to predict convincingness given linguistic features or word embeddings
  \item They show that models can be transferred reasonably well between topics in online debates (78\% accuracy)
  \item New types of text, new domains, and new users with different preferences means we may face situations in practice where models trained on existing corpora are less effective, but data for the new task is limited (sparse)
  \item Use two different pipelines consisting of multiple steps: combining crowdsourced data, removing inconsistencies, classification; combining crowdsourced data, ranking using PageRank, regression
  \item In low-data situations, these approaches may underperform, since model uncertainty is not accounted for between each stage, nor in the final predictions, and errors propagate along the pipeline
  \item Training data may also contain errors, which would be propagated through the pipeline (this was avoided in previous work by combining labels from multiple crowdworkers; we should be able to handle the case where this is not possible).
  \item Feature space becomes very large when working with textual features -- can we narrow it down automatically to improve scalability and improve performance?
\end{itemize}

In contrast to previous work, we propose to directly model the relationship between preferences for convincing arguments and textual features (incl. word embeddings) to predict which arguments a person will prefer:
\begin{itemize}
  \item Bayesian approaches have been shown to successfully handle situations with small amounts of data, allow transfer of background knowledge through priors, and provide a good basis for actively selecting data
  \item Confidence estimates from Bayesian models account for sparsity and noise in data, as well as uncertainty in the model. This means they do not make overly-confident predictions when training data is small (they know when they don't know).
  \item Bayesian preference learning methods have been proposed but scalable implementations were not developed and models have not been applied to text with large numbers of features
  \item We address the limitations above by adapting Bayesian preference learning approach to argumentation
  \item Introduce stochastic variational inference (SVI) to train the model on large numbers of preferences and documents
  \item Develop gradient-based ARD to identify relevant text features
\end{itemize}

We demonstrate how our preference learning approach can be used to model convincingness of arguments:
\begin{itemize}
  \item Evaluate the performance of our approach against state-of-the art deep learning and SVM methods
  \item Show that Bayesian Gaussian process (GP) models are applicable to performing preference learning over text (existing evaluation of GPs for text is very limited, although they have been used extensively with great success in domains such as Physics, finance, Biology. This is possibly because GPs were seen as more difficult to implement and could not be scaled up until recent advances such as SVI)
  \item Evaluate the ability of each method to handle noisy and sparse data, showing improved performance using our method in the presence of noise and data sparsity
  \item Analyse the features that are most informative when determining convincingness, providing insight into what makes a convincing argument
\end{itemize}

Structure:
\begin{itemize}
  \item Review related work in more detail: on argumentation and persuasion; examples of Bayesian methods for NLP
  \item Method background: preference learning with GPs; scalability of GPs; related work on SVI
  \item Method part 1: proposed approach to scalable Bayesian preference learning
  \item Method part 2: automatic relevance determination: background; our proposed gradient-based method
  \item Experiments 1: comparison with state-of-the art on predicting preference in online debates; error analysis focussing on differences between each method
  \item Experiments 2: study of performance with noisy and sparse data; error analysis highlighting differences in each method
  \item Experiments 3: analysis of informative features for argumentation
  \item Conclusions and future work
\end{itemize}

\section{Related Work}\label{sec:related}

Related work on argumentation and persuasion. Related work on finding reasons for argument convincingness (cite Ivan). Related work on choosing the best argument in sequence \cite{rosenfeld2016providing}\cite{monteserin2013reinforcement}. 

Preference learning from pairwise preferences is effective because it removes the need for humans to provide scores or classifications and allows them to make relevance judgements,
which have been shown to be easier for human annotators in many cases\cite{brochu_active_2007}. Pairwise comparisons also occur in implicit feedback, for example, when a user chooses to click on link from a list of several. They are therefore a useful tool for practical learning from end users. 
However, the pairwise comparisons we observe may not be a perfect representation of their preferences as they may contain noise, leading to inconsistencies where items cannot be ranked in such a way that the ranking agrees with all the observed comparisons. 
Bayesian approaches are suited to handling these problems of data sparsity, noise and bias, 
The Gaussian process (GP) preference learning approach of \cite{chu2005preference} resolves inconsistencies between preferences and provides a way to predict rankings or preferences for 
items for which we have not observed any pairwise comparisons based on the item's features. 
This model assumes that preferences are noisy, i.e. contain some erroneous labels.
particularly as the modular nature of inference algorithms such as Gibb's sampling and variational approximation is suited to extending the model to handle different types of feedback that give indications of some underlying preferences. 

The GP methods require $\mathcal{O}(P_n)$ steps, where $P_n$ is the number of pairs for 
user $n$. 
We use SVI to address scalability in a variational Bayesian framework. 
The modular nature of VB allows us to take advantage of models for feedback of different types
where the input values for each type of feedback do not directly correspond (e.g. explicit user ratings and number of clicks may have different values).
By using SVI, we provide a formal way to deal with scalability that comes with guarantees\cite{hoffman2013stochastic}.
We also estimate the output scale of the GPs, the latent factors, and item bias as part of the 
variational approximation. %not clear what the true advantage of this is?

%%%%% New additions in March 2017

In most scenarios where we wish to make predictions about arguments, 
there is a very large number of input variables potentially associated with each argument in the dataset,
but very sparse observations of these variables. 
To illustrate this, consider a simple bag-of-words representation of the argument text, and a set
of click-data recording which actions each user took when presented with a choice between different pieces of text. 
Given a large vocabulary, the words present in an argument will be a very small subset of possible words. Users will likely see a subset of texts and the recorded choices will be a much smaller subset of 
the possible combinations of texts. 
To make predictions about unobserved preferences when presented with a new text with sparse data,
we require an abstraction from the raw input data, and thus seek a way to embed the texts into a space 
where texts with similar properties are placed close together. In the case of arguments, one property
that may determine whether texts should be close together is that they have similar levels of 
convincingness to similar types of people, in similar contexts. Our proposal therefore produces
a form of argument embedding, driven by convincingness.
%Other work on argument embeddings was carried out by \cite{???}. 
A similar approach to learning latent features, VBMDS, is proposed by \cite{soh2016distance} for learning embeddings using approximate Bayesian techniques, but does not use the embeddings for 
preference learning to find separate person and item embeddings and does not apply this to NLP problems.
Their proposal does, however, show how to combine points with and without side information -- our
input features -- to make predictions about low-dimensional embeddings for unseen data. 
The kernelized probabilistic matrix factorization (KPMF) \cite{zhou2012kernelized} 
proposes a similar approach to VBMDS using GP priors over latent dimensions, but with a simpler
MAP inference scheme, and different likelihood and distance functions. 
% see section 4.1 in soh2016distance for more related work in this area, such as GPLVM.

An important aspect of convincingness is the context in which an argument is made, particularly
as part of a dialogue. The sequence of arguments strongly correlates with their ability to change
the audience's opinions \cite{tan2016winning}, as does the prior stance of the audience\cite{lukin2017argument}. 
In our approach, this context can be represented as input variables that affect the item and person embeddings, where the variables encapsulate the previously seen arguments.
While out-of-scope of the present investigation, future work may investigate the best way to
determine novelty of an argument given a small number of variables representing previously seen arguments.
Another related avenue of improvement is to consider the structure of arguments to select 
argument components -- it may be important to consider not just novelty, but whether claims have 
sufficient support and premises are clearly linked to the claims they support or attack. 
Embedding this structure may require complex graph structures of claims and premises to be represented
as short vectors, and may therefore be a topic of future study. 

Using textual data as inputs to a Gaussian process presents some challenge. 
Firstly, large vocabulary sizes lead to a large number of dimensions, which present problems
when performing automatic relevance determination (ARD) to optimize the model to the most important
features for predicting the target variables. Secondly, kernel functions are not typically learned
or adapted to the data, which means that points with different features that commonly co-occur are
not assigned high covariance, whereas it would be desirable to learn that commonly co-occurring features
indicate similar target values. 
A solution to this problem is to represent input features such as words using vectors of continuous values, i.e. word embeddings. This approach was proposed for performing GP regression on 
text data by \cite{yoshikawa2015non}, who showed how to learn the word embeddings and map document
distributions over word embeddings to points in a reproducing kernel Hilbert space. 
% this is what we need for using probabilistic embeddings? Do current probabilistic/Gaussian embeddings
% just try to infer expected embedding and use it as input to another method? If so, 
% we could see if there is an improvement in using kernel embeddings of distributions. The kernel
% embedding is quite simple actually -- just the expectation of the kernel value with respect to the 
% uncertain variable. The challenge would be to turn this into point value that can be used as 
% input to a NN that uses no explicit kernel function.... or do they do something equivalent?
This approach can be used to obtain document embeddings from word embeddings.

% E.g. product review texts. Training data contains +ve reviews with word "good". Unlabelled data
%contains reviews where "good" and "excellent" co-occur --> generative model learns to associate 
%"excellent" with +ve reviews. A GP regression model with "good" and "excellent" as binary input features
% would not be able to learn to associate "excellent" with +ve reviews through co-occurrence, it would 
% rely on "good" being present. 

The latent features allow us to interpolate between items and people in a low-dimensional embedding space. 
A key question in this latent feature approach is how to model the deviation of individual 
preferences from that predicted by latent features common to multiple people (item deviations
can be modelled through an item mean function).
This deviation occurs when there is still entropy in a user's preferences given the latent features
because the latent features only describe patterns that are common to multiple users.
A simple approach is to allow additional noise with uniform variance at each data point, 
so that all preference patterns are represented by the latent feature vectors of items and people.
However, any individual preference patterns particular to one user must then be represented by additional
latent features that are not activated for any other users. 
An alternative is to use a personal model of preference deviation for each person. 
Given the input features of the items and any state variables relating to the person, 
this model can capture correlations in the deviation for different items for the same person. 
Both the latent person features and the individual noise model can also include any input features of 
the person that change over time, e.g. representing their state and the arguments they have 
previously seen. 
This individual noise model allows us to differentiate preference patterns that are specific to 
one user, when the input features may not otherwise be sufficient to distinguish these users. 

%%%%% End March 2017 additions
