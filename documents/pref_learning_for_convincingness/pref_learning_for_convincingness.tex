\documentclass[11pt,letterpaper]{article}
\usepackage[letterpaper]{geometry}
\usepackage{acl2012}
\usepackage{times}
\usepackage{latexsym}
\usepackage[fleqn]{amsmath}
\usepackage{multirow}
\usepackage{url}
\makeatletter
\newcommand{\@BIBLABEL}{\@emptybiblabel}
\newcommand{\@emptybiblabel}[1]{}
\makeatother
\usepackage[hidelinks]{hyperref}
\DeclareMathOperator*{\argmax}{arg\,max}
\setlength\titlebox{6.5cm}    % Expanding the titlebox

% \documentclass[11pt]{article}
% \usepackage{acl2016}
% \usepackage{times}
% \usepackage{url}
% \usepackage{latexsym}
% 
% \usepackage[fleqn]{amsmath}
% \usepackage{amssymb}
% \usepackage{amstext}
% \usepackage{amsthm}
% 
% \usepackage{cite}

\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{algorithm2e}
\usepackage{array}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{url}
\usepackage{tabularx}
\usepackage{numprint}
\usepackage{multirow}

\newcommand{\bs}{\boldsymbol}  
\newcommand{\wrtd}{\mathrm{d}}

\makeatletter
\makeatother %some sort of hack related to the symbol @

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{ 
Finding Convincing Arguments using Scalable Bayesian Preference Learning
}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\}

\date{}
\begin{document}

\maketitle

\begin{abstract}
%To do: move bits to intro that we have to cut 
% Convincingness: decision-making by extracting the best arguments; analysing opinions & influence by seeing who says what; personalised argumentation, where an agent selects the most persuasive arguments for a target person.
% First three sentences need re-writing completely.
% This is hard because the motivation is still unclear/too complex! Multiple points:
% - modelling argument convincingness is useful (motivation part i)
% - existing methods don't work with small data in new domains (motivating problem part ii)
% - Bayesian approach solves this but needs to be more scalable (can reword this to state our contribution)
% - preference learning allows us to learn from pairwise comparisons including implicit feedback (advantages of our contribution)
% - scalability overcomes previous limitations of Bayesian methods
% A good motivation states an opportunity in 1/2 sentences. Can state limitation of existing solutions.
% Follow immediately with clear statement of contribution.
% Argumentation is a key part of human decision making ...


% However, the challenge is to handle the noise in such preference labels and their limited number. 
%    \item We develop a gradient-based approach to automatic relevance determination that enables us to identify the most informative features for predicting arguments when the input space contains tens of thousands of dimensions % this is too detailed for here -- part of our scalable approach. 
Argumentative texts vary greatly in quality, 
meaning that identifying the most convincing arguments 
on each side of a controversial topic could be highly beneficial for decision making.
To address this problem, we present a scalable Gaussian process approach for preference learning 
and apply the method to predicting argument convincingness. 
While Bayesian methods have been shown to be effective when dealing with small and noisy datasets,
methods such as Gaussian processes (GP) have not previously been applied to argument quality.
A perceived drawback is a lack of scalability, which we address through a new
inference method for GP preference learning using recent advances in stochastic variational inference.
We show how our method can be applied to predict argument convincingness from crowdsourced data, 
outperforming state-of-the-art methods, particularly when the data is sparse or noisy.  
We demonstrate more effective active learning using our Bayesian approach, 
thereby reducing the amount of data required to identify convincing arguments for new users and domains.
Our results also illustrate the value of combining linguistic features with word embeddings to improve performance. 

\end{abstract}

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
%\IEEEpeerreviewmaketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{sections/intro}
\input{sections/method}
\input{sections/experiments}
\input{sections/discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% use section* for acknowledgment
\section*{Acknowledgments}

\cleardoublepage

% \addcontentsline{toc}{chapter}{Bibliography}
%\bibliographystyle{apalike}
\bibliographystyle{acl2012}
\bibliography{simpson_pref_learning_for_convincingness}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\appendix
\input{sections/appendix}

\end{document}
