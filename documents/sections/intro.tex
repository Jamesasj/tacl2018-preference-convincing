\section{Introduction}\label{sec:intro}

We hypothesise that different people find different types of argument more convincing than others, and that modelling correlations between different people's convincingness preferences can improve predictions of argument convincingness. 
We aim to establish whether such a model can be learned by observing pairwise convincingness preferences, and whether language features extracted from arguments can further improve performance when which argument a person will find most convincing. 
The experiments evaluate a number of techniques for modelling worker preferences, different types of language features, and the correlations between workers and features. 
We investigate whether workers with similar preferences according to each model give similar justifications for their decisions, thereby lending some additional support for that choice of model.
Part of our evaluation is to assess how models for preference learning can handle large numbers of potentially very sparse features. For example, can we realise the benefits of Bayesian approaches for unsupervised learning and modelling parameter uncertainty, while scaling to large numbers of input features. 
